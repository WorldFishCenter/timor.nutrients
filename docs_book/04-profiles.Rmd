# Timor SSF nutrient profiles {#profiles}

## Methods

In this section, we identified recurrent nutritional profiles based on [RC data](https://worldfishcenter.github.io/timor.nutrients/data.html#data), then, we aimed to predict the nutritional profiles on the basis of the fishing strategy adopted.

### Data analysis design and subset division

As a first step we addressed the inherent imbalance in the [RC data](https://worldfishcenter.github.io/timor.nutrients/data.html#data), a critical aspect for ensuring accurate and unbiased analysis. Notably, a substantial portion of the data, exceeding 40%, is from Atauro, with gill net being the most frequently reported gear type across all the municipalities. To mitigate the skew caused by this overrepresentation, we strategically divided the dataset into four distinct subsets:

-   Atauro - Gill net: Focused on data from Atauro using gill nets.

-   Atauro - All gears: Included data from Atauro using fishing methods other than gill nets.

-   Mainland - Gill net: Comprised of gill net data from all municipalities excluding Atauro.

-   Mainland - All gears: Encompassed data from all other municipalities using non-gill net fishing methods.

This deliberate subdivision of the dataset was intended to reduce bias and enhance analytical precision. Furthermore, by isolating gill net data, we were able to specifically examine the impact of mesh size on the prediction of nutrient profiles in gill net catches, providing a more focused and detailed analysis of this gear type's influence on nutritional outcomes.

Subsequently, we identified recurrent nutritional profiles for each dataset. We assessed the total within sum of square (WSS) of six nutrient concentrations---excluding selenium---to identify the optimal number of distinctive nutritional profiles, or clusters. This approach helped determine the point at which additional data points do not significantly enhance the clarity of the clusters.

Having established the optimal number of clusters, we then performed the K-means clustering method. This method, known for its effectiveness in organizing data into distinct groups based on similarities, was applied to categorize the fishing trips. Each trip was grouped based on its nutrient concentration profile, thereby enabling us to discern patterns and categorize trips according to their nutritional value.

The K-means algorithm functions by assigning each data point to the nearest cluster, based on the mean value of the points in the cluster. This iterative process continues until the assignment of points to clusters no longer changes, indicating that the clusters are as distinct as possible. The result is a set of clusters that represent unique nutritional profiles, each characterized by a specific combination of nutrient concentrations.

Following the clustering, we performed a XGBoost model to predict the nutritional profiles based on the fishing strategy, habitat and season. We employed the XGBoost algorithm due to its effectiveness in preventing overfitting and its ability to highlight key predictors. We used mesh size, habitat, quarter of the year, and vessel type as predictors for gill net subsets. For other gear types, the models used habitat x gear interaction, habitat, gear type, quarter of the year, and vessel type as predictors.

Model tuning was conducted dynamically, adjusting parameters like the number of trees, tree depth, loss reduction, sample size, and early stopping. The data was split into training (80%) and testing (20%) sets, with 10-fold cross-validation applied to the training set for enhanced accuracy and generalizability.

The model's performance was assessed using metrics such as accuracy, ROC AUC, sensitivity, and specificity, providing a comprehensive understanding of its ability to accurately distinguish between different nutritional profiles. The ROC curves and AUC values offered an additional layer of model effectiveness evaluation.

## Results (not updated)

### Clusters

The scatter plot from the k-means clustering (Figure 5.1) showed the distribution of nutrient profiles across different clusters. The first two principal components explained a significant portion of the variance, indicating distinct groupings in nutrient profiles among the fishing trips. The clear separation of clusters in this plot suggests that the fishing trips could be effectively categorized based on their nutrient content. The bar chart (Figure 5.2) displaying nutrient adequacy across clusters indicated the number of individuals meeting the Recommended Nutrient Intake (RNI) per 1kg of catch for various nutrients. The segmentation of bars into different nutrients (calcium, iron, omega-3, protein, vitamin A, zinc) across clusters showed variation in nutritional fulfillment. This suggests that different fishing strategies, represented by different clusters, result in catches with varying nutritional values.

```{r echo=FALSE, fig.cap="Cluster analysis of nutrient profiles using k-means clustering. The scatter plot visualizes the distribution of data points in a two-dimensional space defined by the first two principal components which explain 39% and 26% of the variance. The convex hulls represent the boundaries of each cluster, providing a visual guide to the cluster density and separation.", fig.height=5, fig.width=8, message=FALSE, warning=FALSE}
library(ggplot2)

df <-
  timor.nutrients::kobo_trips %>%
  dplyr::ungroup() %>%
  dplyr::select(-Selenium_mu) %>%
  rename_nutrients_mu() %>%
  tidyr::pivot_longer(c(zinc:vitaminA), names_to = "nutrient", values_to = "kg") %>%
  dplyr::left_join(RDI_tab, by = "nutrient") %>%
  dplyr::mutate(
    nutrients_kg_per_kg = kg / weight, # standardize nutrients for 1 kg of catch
    nutrients_g_per_kg = nutrients_kg_per_kg * 1000, # convert stand nutrients in grams
    people_rni_kg = nutrients_g_per_kg / conv_factor
  ) %>%
  dplyr::select(landing_id, reporting_region, landing_date, vessel_type, habitat, gear_type, nutrient, people_rni_kg) %>%
  tidyr::pivot_wider(names_from = "nutrient", values_from = "people_rni_kg") %>%
  dplyr::mutate(quarter = lubridate::quarter(landing_date)) %>%
  dplyr::select(landing_date, quarter, dplyr::everything()) %>%
  # dplyr::filter(landing_period > "2019-01-01") %>%
  dplyr::group_by(landing_date, quarter, vessel_type, habitat, gear_type) %>%
  dplyr::summarise(dplyr::across(is.numeric, ~ median(.x, na.rm = T))) %>%
  dplyr::ungroup() %>%
  na.omit()

# factoextra::fviz_nbclust(df[ ,5:10], kmeans, method = "wss")
set.seed(555)
k2 <- kmeans(df[, 6:11], centers = 5, nstart = 500)


factoextra::fviz_cluster(k2,
  data = df[, 6:11],
  geom = c("point"),
  shape = 19
) +
  theme_minimal() +
  scale_fill_viridis_d() +
  scale_color_viridis_d() +
  labs(title = "") +
  theme(legend.position = "bottom")
```

```{r echo=FALSE, fig.cap="Distribution of nutrient adequacy across k-means clusters. The bar chart represents the number of individuals meeting the Recommended Nutrient Intake (RNI) per 1kg of catch for each nutrient within different clusters. Each bar is segmented into six categories corresponding to the nutrients analyzed: calcium (dark purple), iron (blue), omega-3 (green), protein (teal), vitamin A (dark teal), and zinc (yellow). Clusters are labeled on the y-axis, indicating distinct groupings based on nutrient profile similarities derived from the cluster analysis. The x-axis quantifies the number of individuals who meet the RNI, highlighting the variation in nutritional fulfillment across clusters.", fig.height=5, fig.width=6, message=FALSE, warning=FALSE}
clusterdf <-
  dplyr::tibble(
    clusters = as.character(k2$cluster),
    df
  )

clusterdf %>%
  # dplyr::select(-weight) %>%
  tidyr::pivot_longer(c(zinc:vitaminA)) %>%
  dplyr::group_by(clusters, name) %>%
  dplyr::summarise(value = median(value, na.rm = T)) %>%
  ggplot(aes(value, reorder(clusters, value), fill = name)) +
  theme_minimal() +
  geom_col() +
  scale_fill_viridis_d() +
  coord_cartesian(expand = FALSE) +
  theme(legend.position = "bottom") +
  labs(x = "N. individuals meeting RNI per 1kg of catch", y = "Cluster number", fill = "")


# generate data for ML model
clusterdf %>% 
  dplyr::mutate(habitat_gear = paste(habitat, gear_type, sep = "_")) %>% 
  dplyr::select(quarter, habitat_gear, habitat, gear_type, vessel_type, cluster = clusters) %>% 
  readr::write_rds(file = paste0(system.file("model-outputs", package = "timor.nutrients"), "/ml_data.rds"))

```

### XGBoost model

The model's predictive capacity was quantitatively assessed via receiver operating characteristic (ROC) analysis across five distinct clusters. The ROC curves (see [ML model interpretation][In simple terms]) illustrate a differential capacity of the model to classify each cluster based on the nutritional profiles derived from various fishing strategies. Cluster 2 and 5 demonstrated superior model performance, indicated by a curve proximate to the top-left, suggesting high sensitivity and specificity. Clusters 1 and 4 showed marginally lower but comparable discrimination ability. Cluster 3 indicated a slight decrease in sensitivity and exhibited the model's lowest performance, with a curve markedly farther from the ideal top-left position. Collectively, an aggregate AUC of 0.87 signifies a strong overall ability of the model to differentiate between the clusters, albeit with varying degrees of precision. These findings underscore the model's effectiveness in predicting nutritional outcomes based on fishing strategies, with implications for tailoring nutrient-sensitive fisheries management interventions.

```{r model-settings, echo=FALSE, fig.cap="Receiver Operating Characteristic (ROC) Curves with Data Points for Cluster-Based Classification. The curves delineate the sensitivity versus 1-specificity for the five clusters derived from the XGBoost classification model. Each cluster is represented by a distinct color with data points marked, which illustrates the true positive rate against the false positive rate for each respective cluster. The closeness of each curve to the top-left corner indicates the model’s classification efficacy per cluster, with Cluster 1 and 2 showing the highest performance. The overall model demonstrates substantial predictive accuracy with a composite AUC value of 0.86.", fig.height=5, fig.width=6, message=FALSE, warning=FALSE}
df_field <-
  readr::read_rds(paste0(system.file("model-outputs", package = "timor.nutrients"), "/ml_data.rds")) %>% 
  dplyr::mutate_all(as.factor)

# DataExplorer::plot_intro(df)
# DataExplorer::plot_bar(df)

# splitting and resampling
set.seed(234)
df_split <-
  df_field %>%
  rsample::initial_split(prop = 0.8, strata = cluster)

train <- rsample::training(df_split)
test <- rsample::testing(df_split)

# Cross validation folds from training dataset
set.seed(567)
folds <- rsample::vfold_cv(train, strata = cluster)

# pre- processing
cust_rec <-
  recipes::recipe(cluster ~ ., data = train) %>%
  #  update_role(customerID, new_role = "ID") %>%
  #  step_corr(all_numeric()) %>%
  recipes::step_corr(recipes::all_numeric(), threshold = 0.7, method = "spearman") %>%
  recipes::step_zv(recipes::all_numeric()) %>% # filter zero variance
  # recipes::step_normalize(recipes::all_numeric()) %>%
  recipes::step_other(habitat, gear_type, habitat_gear) %>%
  recipes::step_dummy(recipes::all_nominal_predictors()) %>%
  themis::step_smote(cluster)

# define model
xgb_spec <- parsnip::boost_tree(
  trees = hardhat::tune(),
  tree_depth = hardhat::tune(),
  min_n = hardhat::tune(),
  loss_reduction = hardhat::tune(), ## first three: model complexity
  sample_size = hardhat::tune(),
  mtry = hardhat::tune(), ## randomness
  learn_rate = hardhat::tune(), ## step size
  stop_iter = hardhat::tune()
  ) %>%
  parsnip::set_engine("xgboost") %>%
  parsnip::set_mode("classification")

# Passing to workflow formula and Model specification
xgb_wf <-
  workflows::workflow() %>%
  workflows::add_formula(cluster ~ .) %>%
  workflows::add_model(xgb_spec)


# tuning
xgb_grid <- dials::grid_latin_hypercube(
  dials::trees(),
  dials::tree_depth(),
  dials::min_n(),
  dials::loss_reduction(),
  dials::sample_prop(),
  dials::learn_rate(),
  dials::stop_iter(),
  dials::finalize(dials::mtry(), train),
  size = 20
)

# choose model performance metrics
members_metrics <- yardstick::metric_set(
  yardstick::accuracy,
  yardstick::roc_auc,
  yardstick::sens,
  yardstick::spec
)


#doParallel::registerDoParallel(cores = 6)
#set.seed(891)
#xgb_res <- tune::tune_grid(
#  xgb_wf,
#  resamples = folds,
#  grid = xgb_grid,
#  control = tune::control_grid(save_pred = TRUE)
#)

#readr::write_rds(xgb_res, file = paste0(system.file("model-outputs", package = #"timor.nutrients"), "/xgb_res.rds"))

# dysplay tuning parameters
# xgb_res %>%
#  tune::collect_metrics() %>%
#  dplyr::filter(.metric == "roc_auc") %>%
#  dplyr::select(mean, mtry:sample_size) %>%
#  tidyr::pivot_longer(mtry:sample_size,
#                      names_to = "parameter",
#                      values_to = "value"
#  ) %>%
#  ggplot(aes(value, mean, color = parameter)) +
#  geom_point(show.legend = FALSE) +
#  facet_wrap(~parameter, scales = "free_x")


# tune::show_best(xgb_res, "roc_auc")

# select best tune
xgb_res <- readr::read_rds(paste0(system.file("model-outputs", package = "timor.nutrients"), "/xgb_res.rds"))
best_auc <- tune::select_best(xgb_res, "roc_auc")

final_xgb <- tune::finalize_workflow(xgb_wf, best_auc)

# final_xgb %>%
#  fit(data = train) %>%
#  hardhat::extract_fit_parsnip() %>%
#  vip::vip(geom = "point")

# fit
final_rs <- tune::last_fit(final_xgb, df_split, metrics = members_metrics)

# final_rs %>%
#  tune::collect_metrics()

cmat <-
  final_rs %>%
  tune::collect_predictions() %>%
  yardstick::conf_mat(cluster, .pred_class)

# show roc curves
final_rs %>%
  tune::collect_predictions() %>%
  yardstick::roc_curve(cluster, c(.pred_1:.pred_5), event_level = "second") %>%
  ggplot(aes(1 - specificity, sensitivity, color = .level)) +
  theme_minimal() +
  geom_line() +
  geom_point(size = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "grey", linetype = "dashed")+
  coord_cartesian(expand = FALSE)+
  scale_color_viridis_d() +
  labs(color = "cluster")

# show auc value
final_rs %>%
  tune::collect_predictions() %>%
  yardstick::roc_auc(cluster, c(.pred_1:.pred_5)) %>% 
  janitor::clean_names() %>% 
  dplyr::mutate(estimate = round(estimate, 2)) %>% 
  knitr::kable()
```

```{r model-explanation, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
fit2 <-
  final_xgb %>%
  fit(data = train)


feat_names <- c("quarter", "habitat_gear", "habitat", "gear_type", "vessel_type")
simple_fit <-
  final_xgb %>%
  fit(data = train)

# Set up parallel backend
doParallel::registerDoParallel(cores = 6)

ks <- kernelshap::kernelshap(
  simple_fit,
  X = train, # Assuming random row order
  bg_X = head(train, 500), # Assuming random row order
  type = "prob", # Predictions must be numeric
  feature_names = feat_names,
  parallel = TRUE,
  verbose = TRUE
)

sha <- shapviz::shapviz(ks)
shapviz::sv_importance(sha) +
  theme_minimal()


shapviz::sv_dependence(sha$.pred_1, "mesh")
```

## Checks and limitations

-   The distribution of both habitat types and gear types in our data is uneven. Observations in deep water and reef environments are more common compared to other habitats, and similarly, the use of gill nets is more frequent than other types of fishing gear. We need to evaluate whether this imbalance could lead to biases or issues in our model.

-   Are we considering all the possible potential good predictors?

-   These color are confusing sometimes, consider change the color palette

## Next steps

Explore the model:

-   Quantify the importance of each predictor on the model outcome

-   Assess the direction of the effect of each predictor, that is analyze which features have the most impact on driving predictions towards each cluster. [SHAP Values][In simple terms] are a good way to address that.
